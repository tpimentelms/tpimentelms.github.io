pub_date	title	authors	venue	excerpt	citation	url_slug	paper_url	abstract	bibtex	bibtype	bibid	year	pages	doi	volume	number
2013-03-02	Mapping planetary caves with an autonomous, heterogeneous robot team	Ammar Husain, Heather Jones, Balajee Kannan, Uland Wong, Tiago Pimentel, Sarah Tang, Shreyansh Daftry, Steven Huber, William L. Whittaker	IEEE Aerospace Conference	This paper is about multi-robot exploration. It presents a framework for coordinating and allocating tasks to an heterogeneous group of robots.	Husain A, Jones H, Kannan B, Wong U, Pimentel T, Tang S, Daftry S, Huber S, Whittaker WL. Mapping planetary caves with an autonomous, heterogeneous robot team. In: IEEE Aerospace Conference, 2013 Mar 2 (pp. 1-13). IEEE.	mapping-planetary-caves	https://ieeexplore.ieee.org/document/6497363	Caves on other planetary bodies offer sheltered habitat for future human explorers and numerous clues to a planet's past for scientists. While recent orbital imagery provides exciting new details about cave entrances on the Moon and Mars, the interiors of these caves are still unknown and not observable from orbit. Multi-robot teams offer unique solutions for exploration and modeling subsurface voids during precursor missions. Robot teams that are diverse in terms of size, mobility, sensing, and capability can provide great advantages, but this diversity, coupled with inherently distinct low-level behavior architectures, makes coordination a challenge. This paper presents a framework that consists of an autonomous frontier and capability-based task generator, a distributed market-based strategy for coordinating and allocating tasks to the different team members, and a communication paradigm for seamless interaction between the different robots in the system. Robots have different sensors, (in the representative robot team used for testing: 2D mapping sensors, 3D modeling sensors, or no exteroceptive sensors), and varying levels of mobility. Tasks are generated to explore, model, and take science samples. Based on an individual robot's capability and associated cost for executing a generated task, a robot is autonomously selected for task execution. The robots create coarse online maps and store collected data for high resolution offline modeling. The coordination approach has been field tested at a mock cave site with highly-unstructured natural terrain, as well as an outdoor patio area. Initial results are promising for applicability of the proposed multi-robot framework to exploration and modeling of planetary caves.	@INPROCEEDINGS{husain2013mapping,   author={     Ammar Husain and     Heather Jones and     Balajee Kannan and     Uland Wong and     Tiago Pimentel and     Sarah Tang and     Shreyansh Daftry and     Steven Huber and     William L. Whittaker   },   booktitle={2013 IEEE Aerospace Conference},   title={Mapping planetary caves with an autonomous, heterogeneous robot team},   year={2013},   volume={},   number={},   pages={1-13}, }	inproceedings	husain2013mapping	2013	1-13			
2018-01-01	Detection of bimanual gestures everywhere: Why it matters, what we need and what is missing	Divya Shah, Ernesto Denicia, Tiago Pimentel, Barbara Bruno, Fulvio Mastrogiovanni	Robotics and Autonomous Systems		Shah D, Denicia E, Pimentel T, Bruno B, Mastrogiovanni F. Detection of bimanual gestures everywhere: Why it matters, what we need and what is missing. In: Robotics and Autonomous Systems. 2018 99:30-49.	detection-of-bimanual-gestures	http://www.sciencedirect.com/science/article/pii/S0921889016303773	Bimanual gestures are of the utmost importance for the study of motor coordination in humans and in everyday activities. A reliable detection of bimanual gestures in unconstrained environments is fundamental for their clinical study and to assess common activities of daily living. This paper investigates techniques for a reliable, unconstrained detection and classification of bimanual gestures. The work assumes the availability of inertial data originating from the two hands/arms, builds upon a previously developed technique for gesture modeling based on Gaussian Mixture Modeling (GMM) and Gaussian Mixture Regression (GMR), and compares different modeling and classification techniques, which are based on a number of assumptions inspired by literature about how bimanual gestures are represented and modeled in the brain. Experiments show results related to 5 everyday bimanual activities, which have been selected on the basis of three main parameters: (not) constraining the two hands by a physical tool, (not) requiring a specific sequence of single-hand gestures, being recursive (or not). In the best performing combination of modeling approach and classification technique, we achieve overall accuracy, precision, recall and F1-score above 80%.	@article{shah2018detection, title = "Detection of bimanual gestures everywhere: {W}hy it matters, what we need and what is missing", journal = "Robotics and Autonomous Systems", volume = "99", pages = "30 - 49", year = "2018", issn = "0921-8890", doi = "https://doi.org/10.1016/j.robot.2017.09.016", url = "http://www.sciencedirect.com/science/article/pii/S0921889016303773", author = "Divya Shah and Ernesto Denicia and Tiago Pimentel and Barbara Bruno and Fulvio Mastrogiovanni", }	article	shah2018detection	2018	30 - 49	https://doi.org/10.1016/j.robot.2017.09.016	99	
2022-05-01	On the probability–quality paradox in language generation	Clara Meister, Gian Wiher, Tiago Pimentel, Ryan Cotterell	Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)		Clara Meister, Gian Wiher, Tiago Pimentel, and Ryan Cotterell. 2022. On the probability–quality paradox in language generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 36–45, Dublin, Ireland. Association for Computational Linguistics.	meister-et-al-2022a	https://aclanthology.org/2022.acl-short.5/	When generating natural language from neural probabilistic models, high probability does not always coincide with high quality: It has often been observed that mode-seeking decoding methods, i.e., those that produce high-probability text under the model, lead to unnatural language. On the other hand, the lower-probability text generated by stochastic methods is perceived as more human-like. In this note, we offer an explanation for this phenomenon by analyzing language generation through an information-theoretic lens. Specifically, we posit that human-like language should contain an amount of information (quantified as negative log-probability) that is close to the entropy of the distribution over natural strings. Further, we posit that language with substantially more (or less) information is undesirable. We provide preliminary empirical evidence in favor of this hypothesis; quality ratings of both human and machine-generated text—covering multiple tasks and common decoding strategies—suggest high-quality text has an information content significantly closer to the entropy than we would expect by chance.	@inproceedings{meister-etal-2022-high,     title = "On the probability{--}quality paradox in language generation",     author = "Meister, Clara  and       Wiher, Gian  and       Pimentel, Tiago  and       Cotterell, Ryan",     booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",     month = may,     year = "2022",     address = "Dublin, Ireland",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2022.acl-short.5",     doi = "10.18653/v1/2022.acl-short.5",     pages = "36--45",     abstract = "When generating natural language from neural probabilistic models, high probability does not always coincide with high quality: It has often been observed that mode-seeking decoding methods, i.e., those that produce high-probability text under the model, lead to unnatural language. On the other hand, the lower-probability text generated by stochastic methods is perceived as more human-like. In this note, we offer an explanation for this phenomenon by analyzing language generation through an information-theoretic lens. Specifically, we posit that human-like language should contain an amount of information (quantified as negative log-probability) that is close to the entropy of the distribution over natural strings. Further, we posit that language with substantially more (or less) information is undesirable. We provide preliminary empirical evidence in favor of this hypothesis; quality ratings of both human and machine-generated text{---}covering multiple tasks and common decoding strategies{---}suggest high-quality text has an information content significantly closer to the entropy than we would expect by chance.", }	inproceedings	meister-et-al-2022-high	2022	36--45	10.18653/v1/2022.acl-short.5		
2022-05-02	Analyzing Wrap-Up Effects through an Information-Theoretic Lens	Clara Meister, Tiago Pimentel, Thomas Clark, Ryan Cotterell, Roger Levy	Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)		Clara Meister, Tiago Pimentel, Thomas Clark, Ryan Cotterell, and Roger Levy. 2022. Analyzing Wrap-Up Effects through an Information-Theoretic Lens. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 20–28, Dublin, Ireland. Association for Computational Linguistics.	meister-et-al-2022b	https://aclanthology.org/2022.acl-short.3/	Numerous analyses of reading time (RT) data have been undertaken in the effort to learn more about the internal processes that occur during reading comprehension. However, data measured on words at the end of a sentence–or even clause–is often omitted due to the confounding factors introduced by so-called “wrap-up effects,” which manifests as a skewed distribution of RTs for these words. Consequently, the understanding of the cognitive processes that might be involved in these effects is limited. In this work, we attempt to learn more about these processes by looking for the existence–or absence–of a link between wrap-up effects and information theoretic quantities, such as word and context information content. We find that the information distribution of prior context is often predictive of sentence- and clause-final RTs (while not of sentence-medial RTs), which lends support to several prior hypotheses about the processes involved in wrap-up effects.	@inproceedings{meister-etal-2022-analyzing,     title = "Analyzing Wrap-Up Effects through an Information-Theoretic Lens",     author = "Meister, Clara  and       Pimentel, Tiago  and       Clark, Thomas  and       Cotterell, Ryan  and       Levy, Roger",     booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",     month = may,     year = "2022",     address = "Dublin, Ireland",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2022.acl-short.3",     doi = "10.18653/v1/2022.acl-short.3",     pages = "20--28",     abstract = "Numerous analyses of reading time (RT) data have been undertaken in the effort to learn more about the internal processes that occur during reading comprehension. However, data measured on words at the end of a sentence{--}or even clause{--}is often omitted due to the confounding factors introduced by so-called {``}wrap-up effects,{''} which manifests as a skewed distribution of RTs for these words. Consequently, the understanding of the cognitive processes that might be involved in these effects is limited. In this work, we attempt to learn more about these processes by looking for the existence{--}or absence{--}of a link between wrap-up effects and information theoretic quantities, such as word and context information content. We find that the information distribution of prior context is often predictive of sentence- and clause-final RTs (while not of sentence-medial RTs), which lends support to several prior hypotheses about the processes involved in wrap-up effects.", }	inproceedings	meister-et-al-2022-analyzing	2022	20--28	10.18653/v1/2022.acl-short.3		
2022-05-03	Probing for the Usage of Grammatical Number	Karim Lasri, Tiago Pimentel, Alessandro Lenci, Thierry Poibeau, Ryan Cotterell	Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)		Karim Lasri, Tiago Pimentel, Alessandro Lenci, Thierry Poibeau, and Ryan Cotterell. 2022. Probing for the Usage of Grammatical Number. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8818–8831, Dublin, Ireland. Association for Computational Linguistics.	lasri-et-al-2022	https://aclanthology.org/2022.acl-long.603/	A central quest of probing is to uncover how pre-trained models encode a linguistic property within their representations. An encoding, however, might be spurious—i.e., the model might not rely on it when making predictions. In this paper, we try to find an encoding that the model actually uses, introducing a usage-based probing setup. We first choose a behavioral task which cannot be solved without using the linguistic property. Then, we attempt to remove the property by intervening on the model’s representations. We contend that, if an encoding is used by the model, its removal should harm the performance on the chosen behavioral task. As a case study, we focus on how BERT encodes grammatical number, and on how it uses this encoding to solve the number agreement task. Experimentally, we find that BERT relies on a linear encoding of grammatical number to produce the correct behavioral output. We also find that BERT uses a separate encoding of grammatical number for nouns and verbs. Finally, we identify in which layers information about grammatical number is transferred from a noun to its head verb.	@inproceedings{lasri-etal-2022-probing,     title = "Probing for the Usage of Grammatical Number",     author = "Lasri, Karim  and       Pimentel, Tiago  and       Lenci, Alessandro  and       Poibeau, Thierry  and       Cotterell, Ryan",     booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",     month = may,     year = "2022",     address = "Dublin, Ireland",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2022.acl-long.603",     doi = "10.18653/v1/2022.acl-long.603",     pages = "8818--8831",     abstract = "A central quest of probing is to uncover how pre-trained models encode a linguistic property within their representations. An encoding, however, might be spurious{---}i.e., the model might not rely on it when making predictions. In this paper, we try to find an encoding that the model actually uses, introducing a usage-based probing setup. We first choose a behavioral task which cannot be solved without using the linguistic property. Then, we attempt to remove the property by intervening on the model{'}s representations. We contend that, if an encoding is used by the model, its removal should harm the performance on the chosen behavioral task. As a case study, we focus on how BERT encodes grammatical number, and on how it uses this encoding to solve the number agreement task. Experimentally, we find that BERT relies on a linear encoding of grammatical number to produce the correct behavioral output. We also find that BERT uses a separate encoding of grammatical number for nouns and verbs. Finally, we identify in which layers information about grammatical number is transferred from a noun to its head verb.", }	inproceedings	lasri-et-al-2022-probing	2022	8818--8831	10.18653/v1/2022.acl-long.603		
2022-12-01	The Architectural Bottleneck Principle	Tiago Pimentel, Josef Valvoda, Niklas Stoehr, Ryan Cotterell	Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing		Tiago Pimentel, Josef Valvoda, Niklas Stoehr, and Ryan Cotterell. 2022. The Architectural Bottleneck Principle. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 11459–11472, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.	pimentel-etal-2022	https://aclanthology.org/2022.emnlp-main.788/	In this paper, we seek to measure how much information a component in a neural network could extract from the representations fed into it. Our work stands in contrast to prior probing work, most of which investigates how much information a model's representations contain. This shift in perspective leads us to propose a new principle for probing, the architectural bottleneck principle: In order to estimate how much information a given component could extract, a probe should look exactly like the component. Relying on this principle, we estimate how much syntactic information is available to transformers through our attentional probe, a probe that exactly resembles a transformer's self-attention head. Experimentally, we find that, in three models (BERT, ALBERT, and RoBERTa), a sentence's syntax tree is mostly extractable by our probe, suggesting these models have access to syntactic information while composing their contextual representations. Whether this information is actually used by these models, however, remains an open question. 	@inproceedings{pimentel-etal-2022-attentional,     title = "The Architectural Bottleneck Principle",     author = "Pimentel, Tiago  and       Valvoda, Josef  and       Stoehr, Niklas  and       Cotterell, Ryan",     booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",     month = dec,     year = "2022",     address = "Abu Dhabi, United Arab Emirates",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2022.emnlp-main.788",     pages = "11459--11472",     abstract = "", }	inproceedings	pimentel-etal-2022-architectural	2022	11459--11472			
2023-05-01	On the Intersection of Context-Free and Regular Languages	Clemente Pasti, Andreas Opedal, Tiago Pimentel, Tim Vieira, Jason Eisner, Ryan Cotterell	Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics		Clemente Pasti, Andreas Opedal, Tiago Pimentel, Tim Vieira, Jason Eisner, and Ryan Cotterell. 2023. On the Intersection of Context-Free and Regular Languages. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 737–749, Dubrovnik, Croatia. Association for Computational Linguistics.	pasti-etal-2023-intersection	https://aclanthology.org/2023.eacl-main.52/	The Bar-Hillel construction is a classic result in formal language theory. It shows, by a simple construction, that the intersection of a context-free language and a regular language is itself context-free. In the construction, the regular language is specified by a finite-state automaton. However, neither the original construction (Bar-Hillel et al., 1961) nor its weighted extension (Nederhof and Satta, 2003) can handle finite-state automata with ε-arcs. While it is possible to remove ε-arcs from a finite-state automaton efficiently without modifying the language, such an operation modifies the automaton’s set of paths. We give a construction that generalizes the Bar- Hillel in the case the desired automaton has ε-arcs, and further prove that our generalized construction leads to a grammar that encodes the structure of both the input automaton and grammar while retaining the asymptotic size of the original construction.	@inproceedings{pasti-etal-2023-intersection,     title = "On the Intersection of Context-Free and Regular Languages",     author = "Pasti, Clemente  and       Opedal, Andreas  and       Pimentel, Tiago  and       Vieira, Tim  and       Eisner, Jason  and       Cotterell, Ryan",     booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",     month = may,     year = "2023",     address = "Dubrovnik, Croatia",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2023.eacl-main.52",     pages = "737--749",     abstract = "The Bar-Hillel construction is a classic result in formal language theory. It shows, by a simple construction, that the intersection of a context-free language and a regular language is itself context-free. In the construction, the regular language is specified by a finite-state automaton. However, neither the original construction (Bar-Hillel et al., 1961) nor its weighted extension (Nederhof and Satta, 2003) can handle finite-state automata with ε-arcs. While it is possible to remove ε-arcs from a finite-state automaton efficiently without modifying the language, such an operation modifies the automaton{'}s set of paths. We give a construction that generalizes the Bar- Hillel in the case the desired automaton has ε-arcs, and further prove that our generalized construction leads to a grammar that encodes the structure of both the input automaton and grammar while retaining the asymptotic size of the original construction.", }	inproceedings	pasti-etal-2023-intersection	2023	737--749			
2023-05-02	On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation	Tiago Pimentel, Clara Meister, Ryan Cotterell	The Eleventh International Conference on Learning Representations		Tiago Pimentel, Clara Isabel Meister, and Ryan Cotterell. "On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation." The Eleventh International Conference on Learning Representations. 2022.	pimentel-etal-2023-usefulness	https://openreview.net/forum?id=bvpkw7UIRdU	A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality.  Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is  the recently proposed Mauve. In theory, Mauve measures an information-theoretic divergence between two probability distributions over strings: one representing the language generator under evaluation; the other representing the true natural language distribution. Mauve's authors argue that its success comes from the qualitative properties of their proposed divergence.  Yet in practice, as this divergence is uncomputable, Mauve approximates it by measuring the divergence between multinomial distributions over clusters instead, where cluster assignments are attained by grouping strings based on a pretrained language model's embeddings. As we show, however, this is not a tight approximation---in either theory or practice. This begs the question: why does Mauve work so well? In this work, we show that \mauve was right for the wrong reasons, and that its newly proposed divergence is not necessary for its high performance. In fact, classical divergences paired with its proposed cluster-based approximation may actually serve as better evaluation metrics. We finish the paper with a probing analysis; this analysis leads us to conclude that---by encoding syntactic- and coherence-level features of text, while ignoring surface-level features---such cluster-based approximations to string distributions may simply be better for evaluating state-of-the-art language generators.	@inproceedings{pimentel2023on, title={On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation}, author={Tiago Pimentel and Clara Isabel Meister and Ryan Cotterell}, booktitle={The Eleventh International Conference on Learning Representations }, year={2023}, url={https://openreview.net/forum?id=bvpkw7UIRdU} }	inproceedings	pimentel-etal-2023-usefulness	2023				
2023-07-01	A Natural Bias for Language Generation Models	Clara Meister, Wojciech Stokowiec, Tiago Pimentel, Lei Yu, Laura Rimell, Adhiguna Kuncoro	Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)		Clara Meister, Wojciech Stokowiec, Tiago Pimentel, Lei Yu, Laura Rimell, and Adhiguna Kuncoro. 2023. A Natural Bias for Language Generation Models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 243–255, Toronto, Canada. Association for Computational Linguistics.	meister-etal-2023-natural	https://aclanthology.org/2023.acl-short.22/	After just a few hundred training updates, a standard probabilistic model for language generation has likely not yet learnt many semantic or syntactic rules of natural language, making it difficult to estimate the probability distribution over next tokens. Yet around this point, these models have identified a simple, loss-minimising behaviour: to output the unigram distribution of the target training corpus. The use of such a heuristic raises the question: Can we initialise our models with this behaviour and save precious compute resources and model capacity? Here we show that we can effectively endow standard neural language generation models with a separate module that reflects unigram frequency statistics as prior knowledge, simply by initialising the bias term in a model’s final linear layer with the log-unigram distribution. We use neural machine translation as a test bed for this simple technique and observe that it: (i) improves learning efficiency; (ii) achieves better overall performance; and perhaps most importantly (iii) appears to disentangle strong frequency effects by encouraging the model to specialise in non-frequency-related aspects of language.	@inproceedings{meister-etal-2023-natural,     title = "A Natural Bias for Language Generation Models",     author = "Meister, Clara  and       Stokowiec, Wojciech  and       Pimentel, Tiago  and       Yu, Lei  and       Rimell, Laura  and       Kuncoro, Adhiguna",     booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",     month = jul,     year = "2023",     address = "Toronto, Canada",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2023.acl-short.22",     pages = "243--255",     abstract = "After just a few hundred training updates, a standard probabilistic model for language generation has likely not yet learnt many semantic or syntactic rules of natural language, making it difficult to estimate the probability distribution over next tokens. Yet around this point, these models have identified a simple, loss-minimising behaviour: to output the unigram distribution of the target training corpus. The use of such a heuristic raises the question: Can we initialise our models with this behaviour and save precious compute resources and model capacity? Here we show that we can effectively endow standard neural language generation models with a separate module that reflects unigram frequency statistics as prior knowledge, simply by initialising the bias term in a model{'}s final linear layer with the log-unigram distribution. We use neural machine translation as a test bed for this simple technique and observe that it: (i) improves learning efficiency; (ii) achieves better overall performance; and perhaps most importantly (iii) appears to disentangle strong frequency effects by encouraging the model to specialise in non-frequency-related aspects of language.", }	inproceedings	meister-etal-2023-natural	2023	243--255			
2023-07-02	A Measure-Theoretic Characterization of Tight Language Models	Li Du, Lucas Torroba Hennigen, Tiago Pimentel, Clara Meister, Jason Eisner, Ryan Cotterell	Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)		Li Du, Lucas Torroba Hennigen, Tiago Pimentel, Clara Meister, Jason Eisner, and Ryan Cotterell. 2023. A Measure-Theoretic Characterization of Tight Language Models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 9744–9770, Toronto, Canada. Association for Computational Linguistics.	du-etal-2023-measure	https://aclanthology.org/2023.acl-long.543/	Language modeling, a central task in natural language processing, involves estimating a probability distribution over strings. In most cases, the estimated distribution sums to 1 over all finite strings. However, in some pathological cases, probability mass can “leak” onto the set of infinite sequences. In order to characterize the notion of leakage more precisely, this paper offers a measure-theoretic treatment of language modeling. We prove that many popular language model families are in fact tight, meaning that they will not leak in this sense. We also generalize characterizations of tightness proposed in previous works.	@inproceedings{du-etal-2023-measure,     title = "A Measure-Theoretic Characterization of Tight Language Models",     author = "Du, Li  and       Torroba Hennigen, Lucas  and       Pimentel, Tiago  and       Meister, Clara  and       Eisner, Jason  and       Cotterell, Ryan",     booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",     month = jul,     year = "2023",     address = "Toronto, Canada",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2023.acl-long.543",     pages = "9744--9770",     abstract = "Language modeling, a central task in natural language processing, involves estimating a probability distribution over strings. In most cases, the estimated distribution sums to 1 over all finite strings. However, in some pathological cases, probability mass can {``}leak{''} onto the set of infinite sequences. In order to characterize the notion of leakage more precisely, this paper offers a measure-theoretic treatment of language modeling. We prove that many popular language model families are in fact tight, meaning that they will not leak in this sense. We also generalize characterizations of tightness proposed in previous works.", }	inproceedings	du-etal-2023-measure	2023	9744--9770			
2023-07-03	Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation	Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, Yanai Elazar	Findings of the Association for Computational Linguistics: ACL 2023		Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. 2023. Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation. In Findings of the Association for Computational Linguistics: ACL 2023, pages 12284–12314, Toronto, Canada. Association for Computational Linguistics.	mosbach-etal-2023-shot	https://aclanthology.org/2023.findings-acl.779/	Few-shot fine-tuning and in-context learning are two alternative strategies for task adaptation of pre-trained language models. Recently, in-context learning has gained popularity over fine-tuning due to its simplicity and improved out-of-domain generalization, and because extensive evidence shows that fine-tuned models pick up on spurious correlations.Unfortunately, previous comparisons of the two approaches were done using models of different sizes. This raises the question of whether the observed weaker out-of-domain generalization of fine-tuned models is an inherent property of fine-tuning or a limitation of the experimental setup. In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B. Our results show that fine-tuned language models can in fact generalize well out-of-domain. We find that both approaches generalize similarly; they exhibit large variation and depend on properties such as model size and the number of examples, highlighting that robust task adaptation remains a challenge.	@inproceedings{mosbach-etal-2023-shot,     title = "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation",     author = "Mosbach, Marius  and       Pimentel, Tiago  and       Ravfogel, Shauli  and       Klakow, Dietrich  and       Elazar, Yanai",     booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",     month = jul,     year = "2023",     address = "Toronto, Canada",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2023.findings-acl.779",     pages = "12284--12314",     abstract = "Few-shot fine-tuning and in-context learning are two alternative strategies for task adaptation of pre-trained language models. Recently, in-context learning has gained popularity over fine-tuning due to its simplicity and improved out-of-domain generalization, and because extensive evidence shows that fine-tuned models pick up on spurious correlations.Unfortunately, previous comparisons of the two approaches were done using models of different sizes. This raises the question of whether the observed weaker out-of-domain generalization of fine-tuned models is an inherent property of fine-tuning or a limitation of the experimental setup. In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B. Our results show that fine-tuned language models can in fact generalize well out-of-domain. We find that both approaches generalize similarly; they exhibit large variation and depend on properties such as model size and the number of examples, highlighting that robust task adaptation remains a challenge.", }	inproceedings	mosbach-etal-2023-shot	2023	12284--12314			
2023-07-04	On the Efficacy of Sampling Adapters	Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan Wilcox, Ryan Cotterell	Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)		Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan Wilcox, and Ryan Cotterell. 2023. On the Efficacy of Sampling Adapters. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1437–1455, Toronto, Canada. Association for Computational Linguistics.	meister-etal-2023-efficacy	https://aclanthology.org/2023.acl-long.80/	Sampling-based decoding strategies are widely employed for generating text from probabilistic models, yet standard ancestral sampling often results in text that is degenerate or incoherent. To alleviate this issue, various modifications to a model’s sampling distribution, such as top-p or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the token-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of distribution quality (such as perplexity), we find that several precision-emphasizing measures indeed indicate that sampling adapters can lead to probability distributions more aligned with the true distribution. Further, these measures correlate with higher sequence-level quality scores, specifically, Mauve.	@inproceedings{meister-etal-2023-efficacy,     title = "On the Efficacy of Sampling Adapters",     author = "Meister, Clara  and       Pimentel, Tiago  and       Malagutti, Luca  and       Wilcox, Ethan  and       Cotterell, Ryan",     booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",     month = jul,     year = "2023",     address = "Toronto, Canada",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2023.acl-long.80",     pages = "1437--1455",     abstract = "Sampling-based decoding strategies are widely employed for generating text from probabilistic models, yet standard ancestral sampling often results in text that is degenerate or incoherent. To alleviate this issue, various modifications to a model{'}s sampling distribution, such as top-p or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the token-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of distribution quality (such as perplexity), we find that several precision-emphasizing measures indeed indicate that sampling adapters can lead to probability distributions more aligned with the true distribution. Further, these measures correlate with higher sequence-level quality scores, specifically, Mauve.", }	inproceedings	meister-etal-2023-efficacy	2023	1437--1455			
2023-02-01	Locally Typical Sampling	Clara Meister, Tiago Pimentel, Gian Wiher, Ryan Cotterell	Transactions of the Association for Computational Linguistics, Volume 11		Clara Meister, Tiago Pimentel, Gian Wiher, and Ryan Cotterell. 2023. Locally Typical Sampling. Transactions of the Association for Computational Linguistics, 11:102–121.	meister-etal-2023-locally	https://aclanthology.org/2023.tacl-1.7/	Today’s probabilistic language generators fall short when it comes to producing coherent and fluent text despite the fact that the underlying models perform well under standard metrics (e.g., perplexity). This discrepancy has puzzled the language generation community for the last few years. In this work, we posit that the abstraction of natural language generation as a discrete stochastic process—which allows for an information-theoretic analysis—can provide new insights into the behavior of probabilistic language generators, for example, why high-probability texts can be dull or repetitive. Humans use language as a means of communicating information, aiming to do so in a simultaneously efficient and error-minimizing manner; in fact, psycholinguistics research suggests humans choose each word in a string with this subconscious goal in mind. We formally define the set of strings that meet this criterion: Those for which each word has an information content close to the expected information content, namely, the conditional entropy of our model. We then propose a simple and efficient procedure for enforcing this criterion when generating from probabilistic models, which we call locally typical sampling. Automatic and human evaluations show that, in comparison to nucleus and top-k sampling, locally typical sampling offers competitive performance (in both abstractive summarization and story generation) in terms of quality while consistently reducing degenerate repetitions.	@article{meister-etal-2023-locally,     title = "Locally Typical Sampling",     author = "Meister, Clara  and       Pimentel, Tiago  and       Wiher, Gian  and       Cotterell, Ryan",     journal = "Transactions of the Association for Computational Linguistics",     volume = "11",     year = "2023",     address = "Cambridge, MA",     publisher = "MIT Press",     url = "https://aclanthology.org/2023.tacl-1.7",     doi = "10.1162/tacl_a_00536",     pages = "102--121",     abstract = "Today{'}s probabilistic language generators fall short when it comes to producing coherent and fluent text despite the fact that the underlying models perform well under standard metrics (e.g., perplexity). This discrepancy has puzzled the language generation community for the last few years. In this work, we posit that the abstraction of natural language generation as a discrete stochastic process{---}which allows for an information-theoretic analysis{---}can provide new insights into the behavior of probabilistic language generators, for example, why high-probability texts can be dull or repetitive. Humans use language as a means of communicating information, aiming to do so in a simultaneously efficient and error-minimizing manner; in fact, psycholinguistics research suggests humans choose each word in a string with this subconscious goal in mind. We formally define the set of strings that meet this criterion: Those for which each word has an information content close to the expected information content, namely, the conditional entropy of our model. We then propose a simple and efficient procedure for enforcing this criterion when generating from probabilistic models, which we call locally typical sampling. Automatic and human evaluations show that, in comparison to nucleus and top-k sampling, locally typical sampling offers competitive performance (in both abstractive summarization and story generation) in terms of quality while consistently reducing degenerate repetitions.", }	article	meister-etal-2023-locally	2023	102--121	10.1162/tacl_a_00536	11	
2023-02-02	Naturalistic Causal Probing for Morpho-Syntax	Afra Amini, Tiago Pimentel, Clara Meister, Ryan Cotterell	Transactions of the Association for Computational Linguistics, Volume 11		Afra Amini, Tiago Pimentel, Clara Meister, and Ryan Cotterell. 2023. Naturalistic Causal Probing for Morpho-Syntax. Transactions of the Association for Computational Linguistics, 11:384–403.	amini-etal-2023-naturalistic	https://aclanthology.org/2023.tacl-1.23/	Probing has become a go-to methodology for interpreting and analyzing deep neural models in natural language processing. However, there is still a lack of understanding of the limitations and weaknesses of various types of probes. In this work, we suggest a strategy for input-level intervention on naturalistic sentences. Using our approach, we intervene on the morpho-syntactic features of a sentence, while keeping the rest of the sentence unchanged. Such an intervention allows us to causally probe pre-trained models. We apply our naturalistic causal probing framework to analyze the effects of grammatical gender and number on contextualized representations extracted from three pre-trained models in Spanish, the multilingual versions of BERT, RoBERTa, and GPT-2. Our experiments suggest that naturalistic interventions lead to stable estimates of the causal effects of various linguistic properties. Moreover, our experiments demonstrate the importance of naturalistic causal probing when analyzing pre-trained models. https://github.com/rycolab/naturalistic-causal-probing	@article{amini-etal-2023-naturalistic,     title = "Naturalistic Causal Probing for Morpho-Syntax",     author = "Amini, Afra  and       Pimentel, Tiago  and       Meister, Clara  and       Cotterell, Ryan",     journal = "Transactions of the Association for Computational Linguistics",     volume = "11",     year = "2023",     address = "Cambridge, MA",     publisher = "MIT Press",     url = "https://aclanthology.org/2023.tacl-1.23",     doi = "10.1162/tacl_a_00554",     pages = "384--403",     abstract = "Probing has become a go-to methodology for interpreting and analyzing deep neural models in natural language processing. However, there is still a lack of understanding of the limitations and weaknesses of various types of probes. In this work, we suggest a strategy for input-level intervention on naturalistic sentences. Using our approach, we intervene on the morpho-syntactic features of a sentence, while keeping the rest of the sentence unchanged. Such an intervention allows us to causally probe pre-trained models. We apply our naturalistic causal probing framework to analyze the effects of grammatical gender and number on contextualized representations extracted from three pre-trained models in Spanish, the multilingual versions of BERT, RoBERTa, and GPT-2. Our experiments suggest that naturalistic interventions lead to stable estimates of the causal effects of various linguistic properties. Moreover, our experiments demonstrate the importance of naturalistic causal probing when analyzing pre-trained models. https://github.com/rycolab/naturalistic-causal-probing", }	article	amini-etal-2023-naturalistic	2023	384--403	10.1162/tacl_a_00554	11	
2023-08-01	A Cross-Linguistic Pressure for Uniform Information Density in Word Order	Thomas Hikaru Clark, Clara Meister, Tiago Pimentel, Michael Hahn, Ryan Cotterell, Richard Futrell, Roger Levy	Transactions of the Association for Computational Linguistics			clark-etal-2023-crosslinguistic	https://arxiv.org/abs/2306.03734	While natural languages differ widely in both canonical word order and word order flexibility, their word orders still follow shared cross-linguistic statistical patterns, often attributed to functional pressures. In the effort to identify these pressures, prior work has compared real and counterfactual word orders. Yet one functional pressure has been overlooked in such investigations: the uniform information density (UID) hypothesis, which holds that information should be spread evenly throughout an utterance. Here, we ask whether a pressure for UID may have influenced word order patterns cross-linguistically. To this end, we use computational models to test whether real orders lead to greater information uniformity than counterfactual orders. In our empirical study of 10 typologically diverse languages, we find that: (i) among SVO languages, real word orders consistently have greater uniformity than reverse word orders, and (ii) only linguistically implausible counterfactual orders consistently exceed the uniformity of real orders. These findings are compatible with a pressure for information uniformity in the development and usage of natural languages. 		article	clark-etal-2023-crosslinguistic	2023				
2023-08-02	The Effect of Surprisal on Reading Times in 11 Languages	Ethan Gotlieb Wilcox, Tiago Pimentel, Clara Meister, Ryan Cotterell, Roger P. Levy	Transactions of the Association for Computational Linguistics			wilcox-etal-2023-effect	https://arxiv.org/abs/2307.03667	A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages. 		article	wilcox-etal-2023-effect	2023				
2023-08-03	On the Effect of Anticipation on Reading Times	Tiago Pimentel, Clara Meister, Ethan G. Wilcox, Roger Levy, Ryan Cotterell	Transactions of the Association for Computational Linguistics			pimentel-etal-2023-effect	https://arxiv.org/abs/2211.14301	Over the past two decades, numerous studies have demonstrated how less predictable (i.e., higher surprisal) words take more time to read. In general, these studies have implicitly assumed the reading process is purely responsive: Readers observe a new word and allocate time to process it as required. We argue that prior results are also compatible with a reading process that is at least partially anticipatory: Readers could make predictions about a future word and allocate time to process it based on their expectation. In this work, we operationalize this anticipation as a word's contextual entropy. We assess the effect of anticipation on reading by comparing how well surprisal and contextual entropy predict reading times on four naturalistic reading datasets: two self-paced and two eye-tracking. Experimentally, across datasets and analyses, we find substantial evidence for effects of contextual entropy over surprisal on a word's reading time (RT): in fact, entropy is sometimes better than surprisal in predicting a word's RT. Spillover effects, however, are generally not captured by entropy, but only by surprisal. Further, we hypothesize four cognitive mechanisms through which contextual entropy could impact RTs -- three of which we are able to design experiments to analyze. Overall, our results support a view of reading that is not just responsive, but also anticipatory. 		article	pimentel-etal-2023-effect	2023				
2023-06-04	Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models	Karolina Stańczak, Sagnik Ray Choudhury, Tiago Pimentel, Ryan Cotterell, Isabelle Augenstein	PLOS One			stanczak-etal-2023-quantifying	https://arxiv.org/abs/2104.07505	While the prevalence of large pre-trained language models has led to significant improvements in the performance of NLP systems, recent research has demonstrated that these models inherit societal biases extant in natural language. In this paper, we explore a simple method to probe pre-trained language models for gender bias, which we use to effect a multi-lingual study of gender bias towards politicians. We construct a dataset of 250k politicians from most countries in the world and quantify adjective and verb usage around those politicians' names as a function of their gender. We conduct our study in 7 languages across 6 different language modeling architectures. Our results demonstrate that stance towards politicians in pre-trained language models is highly dependent on the language used. Finally, contrary to previous findings, our study suggests that larger language models do not tend to be significantly more gender-biased than smaller ones. 		article	stanczak-etal-2023-quantifying	2023				